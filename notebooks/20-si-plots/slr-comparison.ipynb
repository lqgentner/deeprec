{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Satellite Laser Ranging (SLR) TWSA\n",
    "\n",
    "In this notebook, we compare our TWS reconstruction to a TWS product from IGG Bonn which combines gravity field measurements of SLR and DORIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmcrameri.cm as cmc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dask.diagnostics import ProgressBar\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "import deeprec  # noqa\n",
    "from deeprec import metrics\n",
    "from deeprec.regions import basins\n",
    "from deeprec.utils import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register dask progress bar\n",
    "ProgressBar(minimum=5).register()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats(\"retina\")\n",
    "plt.style.use(ROOT_DIR / \"config/style_paper.mplstyle\")\n",
    "FIGURE_DIR = ROOT_DIR / \"docs/figures/si\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Data Loading\n",
    "\n",
    "Load and combine the different data sets (GRACE, ERA5, WGHM, and our and other reconstructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine our predictions\n",
    "pred_dir = ROOT_DIR / \"models/predictions/ensemble-mixed\"\n",
    "\n",
    "ours_list = []\n",
    "\n",
    "for inp_name in [\"era\", \"era-rdcd\", \"wghm-era\"]:\n",
    "    twsa_ours = xr.open_zarr(pred_dir / f\"ensemble-mixed_{inp_name}_best-mae.zarr\").twsa\n",
    "    ours_list.append(twsa_ours.rename(f\"twsa_ours_{inp_name}\"))\n",
    "ours = xr.merge(ours_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_store = ROOT_DIR / \"data/processed/targets.zarr\"\n",
    "inputs_store = ROOT_DIR / \"data/processed/inputs.zarr\"\n",
    "recs_store = ROOT_DIR / \"data/processed/reconstructions.zarr\"\n",
    "# slr_store = ROOT_DIR / \"data/processed/igg-slr-hybrid.zarr\"\n",
    "slr_store = ROOT_DIR / \"data/processed/igg-slr-hybrid-2.zarr\"\n",
    "\n",
    "tgts = xr.open_zarr(targets_store)\n",
    "inps = xr.open_zarr(inputs_store)\n",
    "slr = xr.open_zarr(slr_store)\n",
    "recs = xr.open_zarr(recs_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample SLR data set from 1° to 0.5°\n",
    "step = 0.5\n",
    "lat_05 = np.arange(89.75, -89.75 - step, -step)\n",
    "lon_05 = np.arange(-179.75, 179.75 + step, step)\n",
    "slr = slr.interp(lat=lat_05, lon=lon_05, method=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all data sets\n",
    "ds_all = xr.merge([tgts, inps, slr, recs, ours])\n",
    "\n",
    "# Create and apply mask (land area and Greenland+Antarctica exclusion)\n",
    "mask = (tgts.land_mask_jpl * tgts.land_mask_gsfc * inps.grl_ata_mask).compute()\n",
    "ds_all = ds_all.where(mask == 1)\n",
    "\n",
    "# Substract the GRACE baseline\n",
    "baseline = slice(\"2004\", \"2009\")\n",
    "base_mean = ds_all.sel(time=baseline).mean(\"time\")\n",
    "ds_all = ds_all - base_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify variables of interest and their descriptive names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_verbose = {\n",
    "    \"twsa_ours_era-rdcd\": \"DeepRec, 4×ERA5\",\n",
    "    \"twsa_ours_era\": \"DeepRec, 14×ERA5\",\n",
    "    \"twsa_ours_wghm-era\": \"DeepRec, WGHM+14×ERA5\",\n",
    "    \"twsa_gap\": \"WGHM\",\n",
    "    \"humphrey_gsfc_detrend\": \"Humphrey's GSFC Rec\",\n",
    "    \"li_csr_full\": \"Li's CSR Rec\",\n",
    "    \"yin_csr_full\": \"Yin's CSR Rec\",\n",
    "    \"palazzoli_jpl_full\": \"Palazzoli's JPL Rec\",\n",
    "    \"twsa_csr\": \"CSR (GRACE)\",\n",
    "}\n",
    "eval_names = vars_verbose.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grace_name = \"twsa_csr\"\n",
    "# slr_name = \"twsa_slr_gauss\"\n",
    "slr_name = \"twsa_slr_2024\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove time steps not available in the evaluation product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_slrtime = ds_all[[*eval_names, slr_name]].where(slr.time, drop=True).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate basin averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dims: (\"model\", \"region\")\n",
    "ds_basin = (\n",
    "    # Basins over 200,000 km²\n",
    "    ds_slrtime.chunk(lat=-1, lon=-1, time=10)\n",
    "    .dr.select_basins(top=72)\n",
    "    .dr.weight_lat()\n",
    "    .mean([\"lat\", \"lon\"])\n",
    ").compute()\n",
    "ds_basin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Pre-GRACE and GRACE periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_basin_pre = ds_basin.drop_vars(grace_name).sel(time=slice(None, \"2001\"))\n",
    "ds_basin_post = ds_basin.sel(time=slice(\"2002\", None))\n",
    "# Drop time stamps which are not available for at least one variable\n",
    "ds_basin_pre = ds_basin_pre.where(ds_basin_pre.dr.time_notnull(\"region\"), drop=True)\n",
    "ds_basin_post = ds_basin_post.where(ds_basin_post.dr.time_notnull(\"region\"), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_basin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_pre = ds_basin_pre.get_index(\"time\")\n",
    "print(f\"Timespan pre-GRACE: {times_pre[0].date()} to {times_pre[-1].date()}\")\n",
    "\n",
    "times_post = ds_basin_post.get_index(\"time\")\n",
    "print(f\"Timespan post-GRACE: {times_post[0].date()} to {times_post[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basin scale PCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PCC for pre-GRACE era\n",
    "da_pcc_pre = metrics.pearson_r(\n",
    "    # Model are evaluated, SLR is the truth\n",
    "    ds_basin_pre.drop_vars(slr_name),\n",
    "    ds_basin_pre[slr_name],\n",
    "    dim=\"time\",\n",
    "    skipna=True,\n",
    ").to_dataarray(\"model\")\n",
    "\n",
    "# Calculate PCC for GRACE era\n",
    "da_pcc_post = metrics.pearson_r(\n",
    "    # Model are evaluated, SLR is the truth\n",
    "    ds_basin_post.drop_vars(slr_name),\n",
    "    ds_basin_post[slr_name],\n",
    "    dim=\"time\",\n",
    "    skipna=True,\n",
    ").to_dataarray(\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine along new `era` dimension\n",
    "pcc_basin = xr.concat(\n",
    "    [da_pcc_pre, da_pcc_post], dim=pd.Index([\"pre\", \"post\"], name=\"era\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoDataFrame containing basin shapes and areas\n",
    "gdf_basin_shapes = basins(top=72)\n",
    "\n",
    "# Series of basin areas, for scatter plotting\n",
    "s_basin_areas = gdf_basin_shapes.rename(\n",
    "    columns={\"riverbasin\": \"region\", \"sum_sub_ar\": \"area\"}\n",
    ").set_index(\"region\")[\"area\"]\n",
    "\n",
    "# DataArray of basin areas, for weighting\n",
    "da_basin_areas = xr.DataArray.from_series(s_basin_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pcc_pre_globalavg = (\n",
    "    da_pcc_pre.weighted(da_basin_areas).mean(\"region\").to_pandas().sort_values()\n",
    ")\n",
    "s_pcc_pre_globalavg.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = dict(\n",
    "    col_wrap=2,\n",
    "    coastlines=True,\n",
    "    gridlines=True,\n",
    "    cmap=cmc.lipari_r,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cbar_kwargs=dict(location=\"bottom\", aspect=50, shrink=0.8, pad=0.02, label=\"PCC\"),\n",
    "    rasterized=True,\n",
    "    coastlines_kwargs=dict(rasterized=True, linewidth=0.5),\n",
    ")\n",
    "basinlines_kwargs = dict(\n",
    "    edgecolor=\"black\", linewidth=0.3, facecolor=\"None\", rasterized=True, zorder=3.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy array with the dimensions (model x lat x lon)\n",
    "da_dummy_post = ds_slrtime[eval_names].isel(time=0, drop=True).to_dataarray(\"model\")\n",
    "da_dummy_pre = da_dummy_post.drop_sel(model=grace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = da_pcc_pre.dr.projplot_basins(\n",
    "    da_dummy_pre,\n",
    "    col=\"model\",\n",
    "    figsize=(6, 8.25),\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "# Plot basin shapes\n",
    "for ax, model in zip(p.axs.flat, da_pcc_pre.model.values):\n",
    "    ax.set_title(vars_verbose[model])\n",
    "    gdf_basin_shapes.dr.projplot(ax=ax, **basinlines_kwargs)\n",
    "\n",
    "p.fig.savefig(\n",
    "    FIGURE_DIR / f\"slr_pcc_{times_pre[0].year}-{times_pre[-1].year}.pdf\", backend=\"pgf\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = da_pcc_post.dr.projplot_basins(\n",
    "    da_dummy_post,\n",
    "    col=\"model\",\n",
    "    figsize=(6, 10.25),\n",
    "    **plot_kwargs,\n",
    ")\n",
    "\n",
    "# Plot basin shapes\n",
    "for ax, model in zip(p.axs.flat, da_pcc_post.model.values):\n",
    "    ax.set_title(vars_verbose[model])\n",
    "    gdf_basin_shapes.dr.projplot(ax=ax, **basinlines_kwargs)\n",
    "\n",
    "p.fig.savefig(\n",
    "    FIGURE_DIR / f\"slr_pcc_{times_post[0].year}-{times_post[-1].year}.pdf\",\n",
    "    backend=\"pgf\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
