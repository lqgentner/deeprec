{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics during GRACE era\n",
    "\n",
    "In this notebook, we compare our TWS reconstruction to the GRACE, our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from dask.diagnostics import ProgressBar\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "import deeprec  # noqa\n",
    "from deeprec import metrics\n",
    "from deeprec.regions import basins\n",
    "from deeprec.utils import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register dask progress bar\n",
    "ProgressBar(minimum=5).register()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats(\"retina\")\n",
    "plt.style.use(ROOT_DIR / \"config/style_paper.mplstyle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Data Loading\n",
    "\n",
    "Load and combine the different data sets (GRACE, ERA5, WGHM, and our and other reconstructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine our predictions\n",
    "pred_dir = ROOT_DIR / \"models/predictions/ensemble-mixed\"\n",
    "\n",
    "ours_list = []\n",
    "\n",
    "for inp_name in [\"era\", \"era-rdcd\", \"wghm-era\"]:\n",
    "    twsa_ours = xr.open_zarr(pred_dir / f\"ensemble-mixed_{inp_name}_best-mae.zarr\").twsa\n",
    "    ours_list.append(twsa_ours.rename(f\"twsa_ours_{inp_name}\"))\n",
    "ours = xr.merge(ours_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_store = ROOT_DIR / \"data/processed/targets.zarr\"\n",
    "inputs_store = ROOT_DIR / \"data/processed/inputs.zarr\"\n",
    "recs_store = ROOT_DIR / \"data/processed/reconstructions.zarr\"\n",
    "\n",
    "tgts = xr.open_zarr(targets_store)\n",
    "inps = xr.open_zarr(inputs_store)\n",
    "recs = xr.open_zarr(recs_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all data sets\n",
    "ds_all = xr.merge([tgts, inps, ours])\n",
    "\n",
    "# Create and apply mask (land area and Greenland+Antarctica exclusion)\n",
    "mask = (tgts.land_mask_jpl * tgts.land_mask_gsfc * inps.grl_ata_mask).compute()\n",
    "ds_all = ds_all.where(mask == 1)\n",
    "\n",
    "# Substract the GRACE baseline\n",
    "baseline = slice(\"2004\", \"2009\")\n",
    "base_mean = ds_all.sel(time=baseline).mean(\"time\")\n",
    "ds_all = ds_all - base_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify variables of interest and their descriptive names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_verbose = {\n",
    "    \"twsa_ours_era-rdcd\": \"DeepRec, 4×ERA5\",\n",
    "    \"twsa_ours_era\": \"DeepRec, 14×ERA5\",\n",
    "    \"twsa_ours_wghm-era\": \"DeepRec, WGHM+14×ERA5\",\n",
    "    \"twsa_gap\": \"WGHM\",\n",
    "    \"twsa_csr\": \"CSR (GRACE)\",\n",
    "}\n",
    "eval_names = list(vars_verbose.keys())\n",
    "\n",
    "target_name = \"twsa_csr\"\n",
    "eval_names.remove(target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error and correlation world maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_grid = ds_all[[target_name, *eval_names]]\n",
    "# Only evaluate GRACE time\n",
    "ds_grid = ds_grid.sel(time=slice(\"2002\", \"2023\")).compute()\n",
    "# Remove missing time steps - remove missing time steps in GRACE for all vars\n",
    "ds_grid = ds_grid.where(ds_grid.dr.time_notnull(), drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print time period\n",
    "times = ds_grid.get_index(\"time\")\n",
    "print(f\"Timespan: {times[0].date()} to {times[-1].date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basin averages\n",
    "ds_basin: xr.Dataset = (\n",
    "    # Select variables and time frame of interest\n",
    "    ds_grid.chunk(time=10, lat=-1, lon=-1)\n",
    "    .dr.select_basins(top=72)\n",
    "    .dr.weight_lat()\n",
    "    .mean([\"lat\", \"lon\"])\n",
    "    .compute()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoDataFrame containing basin shapes and areas\n",
    "gdf_basin_shapes = basins(top=72)\n",
    "\n",
    "# Series of basin areas\n",
    "s_basin_areas = gdf_basin_shapes.rename(\n",
    "    columns={\"riverbasin\": \"region\", \"sum_sub_ar\": \"area\"}\n",
    ").set_index(\"region\")[\"area\"]\n",
    "\n",
    "# DataArray of basin areas, for weighting\n",
    "da_basin_areas = xr.DataArray.from_series(s_basin_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and validation periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_train = slice(None, \"2021\")\n",
    "period_val = slice(\"2022\", None)\n",
    "\n",
    "ds_grid_train = ds_grid.sel(time=period_train)\n",
    "ds_grid_val = ds_grid.sel(time=period_val)\n",
    "\n",
    "ds_basin_train = ds_basin.sel(time=period_train)\n",
    "ds_basin_val = ds_basin.sel(time=period_val)\n",
    "\n",
    "# Get start and end years of time series\n",
    "times_train = ds_basin_train.get_index(\"time\")\n",
    "times_val = ds_basin_val.get_index(\"time\")\n",
    "\n",
    "period_train = (times_train[0].year, times_train[-1].year)\n",
    "period_val = (times_val[0].year, times_val[-1].year)\n",
    "\n",
    "print(f\"Timespan Training:   {times_train[0].date()} to {times_train[-1].date()}\")\n",
    "print(f\"Timespan Validation: {times_val[0].date()} to {times_val[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate RMSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "rmse_grid_train = metrics.rmse(\n",
    "    ds_grid_train[target_name], ds_grid_train[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "rmse_basin_train = metrics.rmse(\n",
    "    ds_basin_train[target_name], ds_basin_train[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "rmse_grid_val = metrics.rmse(\n",
    "    ds_grid_val[target_name], ds_grid_val[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "rmse_basin_val = metrics.rmse(\n",
    "    ds_basin_val[target_name], ds_basin_val[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "\n",
    "# Create new partition (part) and model dims\n",
    "da_rmse_grid = xr.concat(\n",
    "    [rmse_grid_train, rmse_grid_val], pd.Index([\"train\", \"val\"], name=\"part\")\n",
    ").to_dataarray(\"model\")\n",
    "da_rmse_basin = xr.concat(\n",
    "    [rmse_basin_train, rmse_basin_val], pd.Index([\"train\", \"val\"], name=\"part\")\n",
    ").to_dataarray(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate global weighted averages\n",
    "da_rmse_grid_avg = (\n",
    "    da_rmse_grid.dr.weight_lat()\n",
    "    .mean([\"lat\", \"lon\"])\n",
    "    .to_dataframe(name=\"score\")\n",
    "    .reset_index()\n",
    ")\n",
    "da_rmse_basin_avg = (\n",
    "    da_rmse_basin.weighted(da_basin_areas)\n",
    "    .mean(\"region\")\n",
    "    .to_dataframe(name=\"score\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating self-explaining text on figure legends\n",
    "legend_renamer = {\n",
    "    \"part\": \"Partition\",\n",
    "    \"train\": f\"Training\\n({period_train[0]}--{period_train[1]})\",\n",
    "    \"val\": f\"Validation\\n({period_val[0]})\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_kwargs = dict(s=40, edgecolors=\"white\")\n",
    "hlines_kwargs = dict(color=\"darkgray\", lw=5, zorder=0, alpha=0.3)\n",
    "\n",
    "# Rename and order model names\n",
    "model_order = (\n",
    "    da_rmse_grid_avg.query(\"part == 'val'\").sort_values(\"score\", ascending=False).model\n",
    ")\n",
    "da_rmse_grid_avg.model = pd.Categorical(\n",
    "    da_rmse_grid_avg.model, categories=model_order, ordered=True\n",
    ").rename_categories(vars_verbose)\n",
    "\n",
    "# Dataframe that saves smallest and largest value per model\n",
    "df_minmax = da_rmse_grid_avg.groupby(\"model\", observed=True).agg(\n",
    "    {\"score\": [\"min\", \"max\"]}\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 2.5))\n",
    "sns.scatterplot(\n",
    "    da_rmse_grid_avg, x=\"score\", y=\"model\", hue=\"part\", ax=ax, **scatter_kwargs\n",
    ")\n",
    "\n",
    "# Connect the dots\n",
    "ax.hlines(\n",
    "    y=df_minmax.index,\n",
    "    xmin=df_minmax.score[\"min\"],\n",
    "    xmax=df_minmax.score[\"max\"],\n",
    "    **hlines_kwargs,\n",
    ")\n",
    "\n",
    "ax.set(ylabel=None, xlabel=\"RMSE (mm)\", xlim=(0, 150))\n",
    "ax.xaxis.grid()\n",
    "ax.legend().remove()\n",
    "legend = fig.legend(loc=\"outside right\")\n",
    "# Replace legend texts\n",
    "for text in legend.texts:\n",
    "    t = text.get_text()\n",
    "    if t in legend_renamer:\n",
    "        t = legend_renamer[t]\n",
    "    text.set_text(t)\n",
    "\n",
    "fig.suptitle(\"Averaged grid scale RMSE\", weight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and order model names\n",
    "model_order = (\n",
    "    da_rmse_basin_avg.query(\"part == 'val'\").sort_values(\"score\", ascending=False).model\n",
    ")\n",
    "da_rmse_basin_avg.model = pd.Categorical(\n",
    "    da_rmse_basin_avg.model, categories=model_order, ordered=True\n",
    ").rename_categories(vars_verbose)\n",
    "\n",
    "# Dataframe that saves smallest and largest value per model\n",
    "df_minmax = da_rmse_basin_avg.groupby(\"model\", observed=True).agg(\n",
    "    {\"score\": [\"min\", \"max\"]}\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 2.5))\n",
    "sns.scatterplot(\n",
    "    da_rmse_basin_avg, x=\"score\", y=\"model\", hue=\"part\", ax=ax, **scatter_kwargs\n",
    ")\n",
    "\n",
    "# Connect the dots\n",
    "ax.hlines(\n",
    "    y=df_minmax.index,\n",
    "    xmin=df_minmax.score[\"min\"],\n",
    "    xmax=df_minmax.score[\"max\"],\n",
    "    **hlines_kwargs,\n",
    ")\n",
    "\n",
    "ax.set(ylabel=None, xlabel=\"RMSE (mm)\", xlim=(0, 70))\n",
    "ax.xaxis.grid()\n",
    "ax.legend().remove()\n",
    "legend = fig.legend(loc=\"outside right\")\n",
    "# Replace legend texts\n",
    "for text in legend.texts:\n",
    "    t = text.get_text()\n",
    "    if t in legend_renamer:\n",
    "        t = legend_renamer[t]\n",
    "    text.set_text(t)\n",
    "\n",
    "fig.suptitle(\"Averaged basin scale RMSE\", weight=\"bold\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSE\n",
    "nse_grid_train = metrics.nse(\n",
    "    ds_grid_train[target_name], ds_grid_train[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "nse_basin_train = metrics.nse(\n",
    "    ds_basin_train[target_name], ds_basin_train[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "nse_grid_val = metrics.nse(\n",
    "    ds_grid_val[target_name], ds_grid_val[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "nse_basin_val = metrics.nse(\n",
    "    ds_basin_val[target_name], ds_basin_val[eval_names], dim=\"time\", skipna=True\n",
    ")\n",
    "\n",
    "# Create new partition (part) and model dims\n",
    "da_nse_grid = xr.concat(\n",
    "    [nse_grid_train, nse_grid_val], pd.Index([\"train\", \"val\"], name=\"part\")\n",
    ").to_dataarray(\"model\")\n",
    "da_nse_basin = xr.concat(\n",
    "    [nse_basin_train, nse_basin_val], pd.Index([\"train\", \"val\"], name=\"part\")\n",
    ").to_dataarray(\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate global weighted averages\n",
    "da_nse_grid_avg = (\n",
    "    da_nse_grid.dr.weight_lat()\n",
    "    .mean([\"lat\", \"lon\"])\n",
    "    .to_dataframe(name=\"score\")\n",
    "    .reset_index()\n",
    ")\n",
    "da_nse_basin_avg = (\n",
    "    da_nse_basin.weighted(da_basin_areas)\n",
    "    .mean(\"region\")\n",
    "    .to_dataframe(name=\"score\")\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and order model names\n",
    "model_order = (\n",
    "    da_nse_basin_avg.query(\"part == 'val'\").sort_values(\"score\", ascending=True).model\n",
    ")\n",
    "da_nse_basin_avg.model = pd.Categorical(\n",
    "    da_nse_basin_avg.model, categories=model_order, ordered=True\n",
    ").rename_categories(vars_verbose)\n",
    "\n",
    "# Dataframe that saves smallest and largest value per model\n",
    "df_minmax = da_nse_basin_avg.groupby(\"model\", observed=True).agg(\n",
    "    {\"score\": [\"min\", \"max\"]}\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 2.5))\n",
    "sns.scatterplot(\n",
    "    da_nse_basin_avg, x=\"score\", y=\"model\", hue=\"part\", ax=ax, **scatter_kwargs\n",
    ")\n",
    "\n",
    "# Connect the dots\n",
    "ax.hlines(\n",
    "    y=df_minmax.index,\n",
    "    xmin=df_minmax.score[\"min\"],\n",
    "    xmax=df_minmax.score[\"max\"],\n",
    "    **hlines_kwargs,\n",
    ")\n",
    "\n",
    "ax.set(ylabel=None, xlabel=\"NSE\")  # , xlim=(, None))\n",
    "ax.xaxis.grid()\n",
    "ax.legend().remove()\n",
    "legend = fig.legend(loc=\"outside right\")\n",
    "# Replace legend texts\n",
    "for text in legend.texts:\n",
    "    t = text.get_text()\n",
    "    if t in legend_renamer:\n",
    "        t = legend_renamer[t]\n",
    "    text.set_text(t)\n",
    "\n",
    "fig.suptitle(\"Averaged basin scale NSE\", weight=\"bold\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmcrameri.cm as cmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = dict(\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    cmap=cmc.bam,\n",
    "    coastlines=True,\n",
    "    gridlines=True,\n",
    "    rasterized=True,\n",
    "    coastlines_kwargs=dict(rasterized=True, linewidth=0.5),\n",
    "    cbar_kwargs=dict(location=\"bottom\", aspect=50, shrink=0.8, pad=0.02, label=\"NSE\"),\n",
    "    figsize=(6, 8.25),\n",
    ")\n",
    "basinlines_kwargs = dict(\n",
    "    edgecolor=\"black\", linewidth=0.4, facecolor=\"None\", rasterized=True, zorder=3.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_nse_basin = da_nse_basin.assign_coords(\n",
    "    part=[legend_renamer[name] for name in da_nse_basin.part.values]\n",
    ").assign_coords(model=[vars_verbose[name] for name in da_nse_basin.model.values])\n",
    "da_nse_grid = da_nse_grid.assign_coords(\n",
    "    part=[legend_renamer[name] for name in da_nse_grid.part.values]\n",
    ").assign_coords(model=[vars_verbose[name] for name in da_nse_grid.model.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_dummy = xr.zeros_like(da_nse_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = da_nse_basin.dr.projplot_basins(da_dummy, row=\"model\", col=\"part\", **plot_kwargs)\n",
    "p.set_titles(\"{value}\")\n",
    "# Plot basin shapes\n",
    "basin_shapes = basins(top=72)\n",
    "for ax in p.axs.flat:\n",
    "    basin_shapes.dr.projplot(ax=ax, **basinlines_kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
