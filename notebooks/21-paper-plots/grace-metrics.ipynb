{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics during GRACE era\n",
    "\n",
    "In this notebook, we compare our TWS reconstruction to the GRACE, our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cmcrameri.cm as cmc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from dask.diagnostics import ProgressBar\n",
    "from matplotlib import ticker\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "import deeprec  # noqa\n",
    "from deeprec import metrics\n",
    "from deeprec.regions import basins\n",
    "from deeprec.utils import ROOT_DIR, repeat_by_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register dask progress bar\n",
    "ProgressBar(minimum=5).register()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats(\"retina\")\n",
    "plt.style.use(ROOT_DIR / \"config/style_paper.mplstyle\")\n",
    "FIGURE_DIR = ROOT_DIR / \"docs/figures/paper\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Data Loading\n",
    "\n",
    "Load and combine the different data sets (GRACE, ERA5, WGHM, and our and other reconstructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_store = (\n",
    "    ROOT_DIR / \"models/predictions/ensemble-mixed/ensemble-mixed_era_best-mae.zarr\"\n",
    ")\n",
    "inputs_store = ROOT_DIR / \"data/processed/inputs.zarr\"\n",
    "targets_store = ROOT_DIR / \"data/processed/targets.zarr\"\n",
    "recs_store = ROOT_DIR / \"data/processed/reconstructions.zarr\"\n",
    "\n",
    "tgts = xr.open_zarr(targets_store)\n",
    "inps = xr.open_zarr(inputs_store)\n",
    "recs = xr.open_zarr(recs_store)\n",
    "our = xr.open_zarr(our_store).twsa.rename(\"twsa_our\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all data sets\n",
    "ds_all = xr.merge([tgts, inps, recs, our])\n",
    "\n",
    "# Create and apply mask (land area and Greenland+Antarctica exclusion)\n",
    "mask = (tgts.land_mask_jpl * tgts.land_mask_gsfc * inps.grl_ata_mask).compute()\n",
    "ds_all = ds_all.where(mask == 1)\n",
    "\n",
    "# Substract the GRACE baseline\n",
    "baseline = slice(\"2004\", \"2009\")\n",
    "base_mean = ds_all.sel(time=baseline).mean(\"time\")\n",
    "ds_all = ds_all - base_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify variables of interest and their descriptive names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_verbose = {\n",
    "    \"twsa_our\": \"DeepRec (Ours)\",\n",
    "    \"twsa_gap\": \"WGHM\",\n",
    "    \"palazzoli_jpl_full\": \"Palazzoli's JPL Rec\",\n",
    "    \"yin_csr_full\": \"Yin's CSR Rec\",\n",
    "    \"li_csr_full\": \"Li's CSR Rec\",\n",
    "    \"humphrey_gsfc_detrend\": \"Humphrey's GSFC Rec\",\n",
    "    \"twsa_csr\": \"CSR (GRACE)\",\n",
    "}\n",
    "target_name = \"twsa_csr\"\n",
    "our_name = \"twsa_our\"\n",
    "\n",
    "eval_names = list(vars_verbose.keys())\n",
    "eval_names.remove(target_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error and correlation world maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_grid = ds_all[[target_name, *eval_names]]\n",
    "# Only evaluate GRACE time\n",
    "ds_grid = ds_grid.sel(time=slice(\"2002\", \"2023\")).compute()\n",
    "\n",
    "# Calculate basin averages\n",
    "ds_basin: xr.Dataset = (\n",
    "    # Select variables and time frame of interest\n",
    "    ds_grid.chunk(time=10, lat=-1, lon=-1)\n",
    "    .dr.select_basins(top=72)\n",
    "    .dr.weight_lat()\n",
    "    .mean([\"lat\", \"lon\"])\n",
    "    .compute()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Ours vs. GRACE (2002-2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing time steps - remove missing time steps in GRACE for all vars\n",
    "ds_grid_our = ds_grid[[target_name, our_name]]\n",
    "ds_grid_our = ds_grid_our.where(ds_grid_our.dr.time_notnull(), drop=True)\n",
    "\n",
    "ds_basin_our = ds_basin[[target_name, our_name]]\n",
    "ds_basin_our = ds_basin_our.where(ds_grid_our.dr.time_notnull(), drop=True)\n",
    "\n",
    "times_our = ds_grid_our.get_index(\"time\")\n",
    "print(f\"Period: {times_our[0].date()} to {times_our[-1].date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "our_rmse_grid = metrics.rmse(\n",
    "    ds_grid_our[target_name], ds_grid_our[our_name], dim=\"time\", skipna=True\n",
    ")\n",
    "our_rmse_basin = metrics.rmse(\n",
    "    ds_basin[target_name], ds_basin[our_name], dim=\"time\", skipna=True\n",
    ")\n",
    "\n",
    "# NSE\n",
    "our_nse_grid = metrics.nse(\n",
    "    ds_grid_our[target_name], ds_grid_our[our_name], dim=\"time\", skipna=True\n",
    ")\n",
    "our_nse_basin = metrics.nse(\n",
    "    ds_basin[target_name], ds_basin[our_name], dim=\"time\", skipna=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics All vs. GRACE (2002-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing time steps - remove missing time steps in GRACE for all vars\n",
    "ds_grid_all = ds_grid[[target_name, *eval_names]]\n",
    "ds_grid_all = ds_grid_all.where(ds_grid_all.dr.time_notnull(), drop=True)\n",
    "\n",
    "ds_basin_all = ds_basin[[target_name, *eval_names]]\n",
    "ds_basin_all = ds_basin_all.where(ds_grid_all.dr.time_notnull(), drop=True)\n",
    "\n",
    "times_all = ds_grid_all.get_index(\"time\")\n",
    "print(f\"Period: {times_all[0].date()} to {times_all[-1].date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "da_rmse_grid = metrics.rmse(\n",
    "    ds_grid[target_name], ds_grid[eval_names], dim=\"time\", skipna=True\n",
    ").to_dataarray(\"model\")\n",
    "da_rmse_basin = metrics.rmse(\n",
    "    ds_basin[target_name], ds_basin[eval_names], dim=\"time\", skipna=True\n",
    ").to_dataarray(\"model\")\n",
    "\n",
    "# NSE\n",
    "da_nse_grid = metrics.nse(\n",
    "    ds_grid[target_name], ds_grid[eval_names], dim=\"time\", skipna=True\n",
    ").to_dataarray(\"model\")\n",
    "da_nse_basin = metrics.nse(\n",
    "    ds_basin[target_name], ds_basin[eval_names], dim=\"time\", skipna=True\n",
    ").to_dataarray(\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_kwargs = dict(\n",
    "    cbar_kwargs=dict(\n",
    "        location=\"right\", aspect=15, shrink=0.93, pad=0.03, label=\"RMSE (mm)\"\n",
    "    ),\n",
    "    cmap=cmc.batlow_r,\n",
    "    coastlines=True,\n",
    "    gridlines=True,\n",
    "    coastlines_kwargs=dict(rasterized=True, linewidth=0.5),\n",
    "    rasterized=True,\n",
    ")\n",
    "nse_kwargs = dict(\n",
    "    cbar_kwargs=dict(location=\"right\", aspect=15, shrink=0.93, pad=0.03, label=\"NSE\"),\n",
    "    cmap=cmc.navia_r,\n",
    "    coastlines=True,\n",
    "    gridlines=True,\n",
    "    coastlines_kwargs=dict(rasterized=True, linewidth=0.5),\n",
    "    rasterized=True,\n",
    ")\n",
    "basinlines_kwargs = dict(\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.4,\n",
    "    facecolor=\"None\",\n",
    "    zorder=3.0,\n",
    "    rasterized=True,\n",
    ")\n",
    "title_kwargs = dict(fontsize=16, weight=\"bold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoDataFrame containing basin shapes and areas\n",
    "gdf_basin_shapes = basins(top=72)\n",
    "\n",
    "# Series of basin areas\n",
    "s_basin_areas = gdf_basin_shapes.rename(\n",
    "    columns={\"riverbasin\": \"region\", \"sum_sub_ar\": \"area\"}\n",
    ").set_index(\"region\")[\"area\"]\n",
    "\n",
    "# DataArray of basin areas, for weighting\n",
    "da_basin_areas = xr.DataArray.from_series(s_basin_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{our_rmse_grid.min() = :.1f}\")\n",
    "print(f\"{our_rmse_grid.max() = :.1f}\\n\")\n",
    "\n",
    "print(f\"{our_nse_grid.min() = :.1f}\")\n",
    "print(f\"{our_nse_grid.max() = :.1f}\\n\")\n",
    "\n",
    "print(f\"{our_rmse_basin.min() = :.1f}\")\n",
    "print(f\"{our_rmse_basin.max() = :.1f}\\n\")\n",
    "\n",
    "print(f\"{our_nse_basin.min() = :.1f}\")\n",
    "print(f\"{our_nse_basin.max() = :.1f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{our_rmse_grid.dr.weight_lat().mean() = :.1f}\")\n",
    "print(f\"{our_rmse_grid.dr.weight_lat().quantile(0.9) = :.1f}\\n\")\n",
    "\n",
    "print(f\"{our_nse_grid.dr.weight_lat().mean() = :.1f}\")\n",
    "print(f\"{our_nse_grid.dr.weight_lat().quantile(0.1) = :.1f}\\n\")\n",
    "\n",
    "print(f\"{our_rmse_basin.weighted(da_basin_areas).mean() = :.1f}\")\n",
    "print(f\"{our_rmse_basin.weighted(da_basin_areas).quantile(0.9) = :.1f}\\n\")\n",
    "\n",
    "print(f\"{our_nse_basin.weighted(da_basin_areas).mean() = :.1f}\")\n",
    "print(f\"{our_nse_basin.weighted(da_basin_areas).quantile(0.1) = :.1f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    2, 2, subplot_kw={\"projection\": ccrs.EqualEarth()}, figsize=(7.2, 3.5)\n",
    ")\n",
    "\n",
    "# Grid scale plots\n",
    "our_rmse_grid.dr.projplot(vmin=0, vmax=100, ax=axs[0][0], **rmse_kwargs)\n",
    "our_nse_grid.dr.projplot(vmin=0.0, vmax=1.0, ax=axs[1][0], **nse_kwargs)\n",
    "\n",
    "# Basin scale plots\n",
    "our_rmse_basin.dr.projplot_basins(\n",
    "    our_rmse_grid,\n",
    "    vmin=0,\n",
    "    vmax=50,\n",
    "    ax=axs[0][1],\n",
    "    **rmse_kwargs,\n",
    ")\n",
    "our_nse_basin.dr.projplot_basins(\n",
    "    our_nse_grid,\n",
    "    vmin=0.7,\n",
    "    vmax=1.0,\n",
    "    ax=axs[1][1],\n",
    "    **nse_kwargs,\n",
    ")\n",
    "\n",
    "# Add basinlines\n",
    "for ax in [axs[0][1], axs[1][1]]:\n",
    "    gdf_basin_shapes.dr.projplot(ax=ax, **basinlines_kwargs)\n",
    "\n",
    "# Titles\n",
    "axs[0][0].set(title=\"Grid scale\")\n",
    "axs[0][1].set(title=\"Basin scale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataArray to DataFrame\n",
    "df_nse = da_nse_basin.to_dataframe(name=\"nse\").reset_index()\n",
    "df_nse[\"model_verbose\"] = df_nse[\"model\"].map(vars_verbose)\n",
    "\n",
    "# Convert area to integer (we define the smallest area as 10)\n",
    "s_basin_ints = (s_basin_areas / s_basin_areas.min() * 10).round().astype(int)\n",
    "\n",
    "# Merge with area integers\n",
    "df_nse_area = df_nse.merge(s_basin_ints, left_on=\"region\", right_index=True)\n",
    "\n",
    "# Create weighted dataframe (columns repeated according to area integers)\n",
    "df_nse_weighted = repeat_by_weight(df_nse_area, \"area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by increasing mean\n",
    "my_order = (\n",
    "    df_nse.groupby(by=[\"model_verbose\"])[\"nse\"]\n",
    "    .mean()\n",
    "    # Sort GRACE to the beginning\n",
    "    .sort_values(na_position=\"first\")\n",
    "    .index\n",
    ")\n",
    "my_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"tab20\")\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for color lookup\n",
    "dark_colors_dict = {\n",
    "    \"twsa_our\": colors[0],\n",
    "    \"twsa_csr\": colors[2],\n",
    "    \"twsa_gap\": colors[4],\n",
    "    \"yin_csr_full\": colors[6],\n",
    "    \"palazzoli_jpl_full\": colors[8],\n",
    "    \"li_csr_full\": colors[10],\n",
    "    \"humphrey_gsfc_detrend\": colors[12],\n",
    "    \"twsa_gmsl_alt\": colors[16],\n",
    "    \"twsa_gmsl_obs\": colors[18],\n",
    "}\n",
    "light_colors_dict = {\n",
    "    \"twsa_our\": colors[1],\n",
    "    \"twsa_csr\": colors[3],\n",
    "    \"twsa_gap\": colors[5],\n",
    "    \"palazzoli_jpl_full\": colors[7],\n",
    "    \"yin_csr_full\": colors[9],\n",
    "    \"li_csr_full\": colors[11],\n",
    "    \"humphrey_gsfc_detrend\": colors[13],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.2, 2.2))\n",
    "sns.boxplot(\n",
    "    df_nse_weighted,\n",
    "    x=\"nse\",\n",
    "    y=\"model_verbose\",\n",
    "    hue=\"model\",\n",
    "    width=0.5,\n",
    "    ax=ax,\n",
    "    order=my_order,\n",
    "    palette=dark_colors_dict,\n",
    "    showfliers=False,\n",
    "    saturation=1,\n",
    "    legend=False,\n",
    ")\n",
    "ax.set(xlabel=\"NSE\", ylabel=None, xlim=(0, 1))\n",
    "ax.xaxis.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar chart\n",
    "\n",
    "Create a bar chart which shows grid scale and basin scale NSE in one chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_rmse_grid_avg = (\n",
    "    da_rmse_grid.dr.weight_lat().mean([\"lat\", \"lon\"]).rename(\"Grid scale RMSE\")\n",
    ")\n",
    "da_rmse_basin_avg = (\n",
    "    da_rmse_basin.weighted(da_basin_areas).mean(\"region\").rename(\"Basin scale RMSE\")\n",
    ")\n",
    "\n",
    "# Concatenate along new \"scale \" dimension\n",
    "da_rmse_avg = xr.concat(\n",
    "    [da_rmse_grid_avg, da_rmse_basin_avg],\n",
    "    pd.Index([\"Grid scale\", \"Basin scale\"], name=\"scale\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse_avg = (\n",
    "    da_rmse_avg.to_pandas()\n",
    "    .rename(columns=vars_verbose)\n",
    "    .reset_index()\n",
    "    .melt(id_vars=\"scale\", value_name=\"rmse\")\n",
    ")\n",
    "df_rmse_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_order = (\n",
    "    df_rmse_avg.query(\"scale == 'Basin scale'\")\n",
    "    .sort_values(\"rmse\", ascending=False)\n",
    "    .model\n",
    ")\n",
    "my_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.2, 3))\n",
    "sns.barplot(\n",
    "    df_rmse_avg,\n",
    "    x=\"rmse\",\n",
    "    y=\"model\",\n",
    "    hue=\"scale\",\n",
    "    width=0.6,\n",
    "    gap=0.1,\n",
    "    ax=ax,\n",
    "    palette=\"Paired\",\n",
    "    order=my_order,\n",
    ")\n",
    "ax.set(xlabel=\"RMSE (mm)\", ylabel=None, xlim=(0, 100))\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.xaxis.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots of signal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform linear trend / multi-seasonal decomposition\n",
    "\n",
    "We use the following function to approximate the constant $a$, the linear trend $b$, and the annual and semi-annual sinusoidal curves:\n",
    "\n",
    "$$\n",
    "y(t) = a + b \\, t + c \\, \\sin(2π  \\, t) + d \\, \\cos(2π \\, t) + e \\, \\sin(4π \\, t) + f \\cos(4π \\, t) + r\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_NS = 365.25 * 24 * 60 * 60 * 1e9\n",
    "\n",
    "\n",
    "def decomp_func(\n",
    "    t: np.ndarray, a: float, b: float, c: float, d: float, e: float, f: float\n",
    ") -> np.ndarray:\n",
    "    # Convert t from nanosecons to years\n",
    "    t = t / YEAR_NS\n",
    "\n",
    "    linear = a + b * t\n",
    "    annual = c * np.sin(2 * np.pi * t) + d * np.cos(2 * np.pi * t)\n",
    "    semian = e * np.sin(4 * np.pi * t) + f * np.cos(4 * np.pi * t)\n",
    "\n",
    "    return linear + annual + semian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply decomposition\n",
    "# Curvefit skips missing values per default\n",
    "fit = ds_basin_our.to_dataarray(\"model\").curvefit(\"time\", decomp_func)\n",
    "fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate slope and amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear trend: mm / yr\n",
    "da_lintrend = fit.curvefit_coefficients.sel(param=\"b\")\n",
    "\n",
    "da_lintrend.attrs = {\"long_name\": \"Trend\", \"unit\": \"mm / yr\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate annual amplitude:\n",
    "\n",
    "$$\n",
    "A = \\sqrt{c^2 + d^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = fit.curvefit_coefficients.sel(param=\"c\")\n",
    "d = fit.curvefit_coefficients.sel(param=\"d\")\n",
    "e = fit.curvefit_coefficients.sel(param=\"e\")\n",
    "f = fit.curvefit_coefficients.sel(param=\"f\")\n",
    "\n",
    "da_amp_annual = np.sqrt(c**2 + d**2)\n",
    "da_amp_semian = np.sqrt(e**2 + f**2)\n",
    "\n",
    "da_amp_annual.attrs = {\"long_name\": \"Annual amplitude\", \"unit\": \"mm\"}\n",
    "da_amp_semian.attrs = {\"long_name\": \"Semi-annual amplitude\", \"unit\": \"mm\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place components in dictionaries for easier batch handling\n",
    "da_comps = {\n",
    "    \"lintrend\": da_lintrend,\n",
    "    \"amp_annual\": da_amp_annual,\n",
    "    \"amp_semian\": da_amp_semian,\n",
    "}\n",
    "df_comps = {}\n",
    "pcc_scores = {}\n",
    "\n",
    "for name, da in da_comps.items():\n",
    "    # Convert DataArrays to DataFrames for plotting with Seaborn\n",
    "    df = (\n",
    "        da.to_pandas()\n",
    "        .transpose()\n",
    "        .reset_index()\n",
    "        # Add basin size column (in Million km)\n",
    "        .merge(s_basin_areas / 1e6, on=\"region\")\n",
    "        # Sort after area so large basins are printed lastly\n",
    "        .sort_values(\"area\")\n",
    "    )\n",
    "    df_comps[name] = df\n",
    "\n",
    "    # Calculate PCC\n",
    "    pcc_scores[name] = metrics.pearson_r(\n",
    "        da.sel(model=target_name), da.sel(model=our_name), weights=da_basin_areas\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units\n",
    "units = {\n",
    "    \"lintrend\": \"mm yr$^-1$\",\n",
    "    \"amp_annual\": \"mm\",\n",
    "    \"amp_semian\": \"mm\",\n",
    "}\n",
    "# Verbose names\n",
    "names_verbose = {\n",
    "    \"lintrend\": \"Linear\\ntrend\",\n",
    "    \"amp_annual\": \"Annual\\namplitude\",\n",
    "    \"amp_semian\": \"Semiannual\\namplitude\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{da_lintrend.min() = :.2f}\")\n",
    "print(f\"{da_lintrend.max() = :.2f}\")\n",
    "\n",
    "print(f\"{da_amp_annual.min() = :.2f}\")\n",
    "print(f\"{da_amp_annual.max() = :.2f}\")\n",
    "\n",
    "print(f\"{da_amp_semian.min() = :.2f}\")\n",
    "print(f\"{da_amp_semian.max() = :.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits\n",
    "lims = {\n",
    "    \"lintrend\": (-20, 10),\n",
    "    \"amp_annual\": (0, 250),\n",
    "    \"amp_semian\": (0, 80),\n",
    "}\n",
    "# Major locators\n",
    "locs = {\n",
    "    \"lintrend\": ticker.MultipleLocator(10),\n",
    "    \"amp_annual\": ticker.MultipleLocator(50),\n",
    "    \"amp_semian\": ticker.MultipleLocator(20),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3, figsize=(7.2, 2.2))\n",
    "\n",
    "for i, (ax, (name, df)) in enumerate(zip(axs, df_comps.items())):\n",
    "    sns.scatterplot(\n",
    "        df,\n",
    "        x=target_name,\n",
    "        y=our_name,\n",
    "        ax=ax,\n",
    "        size=\"area\",\n",
    "        legend=True if i == 0 else False,\n",
    "    )\n",
    "\n",
    "    # Unpack dicts\n",
    "    name_verbose = names_verbose[name]\n",
    "    unit = units[name]\n",
    "    lim = lims[name]\n",
    "    loc = locs[name]\n",
    "    pcc = pcc_scores[name]\n",
    "\n",
    "    ax.set(\n",
    "        title=name_verbose,\n",
    "        xlabel=f\"CSR ({unit})\",\n",
    "        ylabel=f\"DeepRec ({unit})\",\n",
    "        xlim=lim,\n",
    "        ylim=lim,\n",
    "        aspect=\"equal\",\n",
    "    )\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "    # Add diagonal line\n",
    "    ax.plot(\n",
    "        lim,\n",
    "        lim,\n",
    "        color=\"gray\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        zorder=0.0,\n",
    "    )\n",
    "\n",
    "    # Add score\n",
    "    ax.text(1.0, 0.07, f\"PCC = {pcc:.2f}\", ha=\"right\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "# Place legend outside of axes\n",
    "axs[0].legend().remove()\n",
    "legend = fig.legend(loc=\"outside right\", title=\"Area\\n($10^6$ km$^2$)\")\n",
    "legend.get_title().set_ha(\"center\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7.2, 8.0))\n",
    "subfigs = fig.subfigures(nrows=3, hspace=0.05, height_ratios=[1.5, 1, 1.2])\n",
    "\n",
    "axs_geo = subfigs[0].subplots(2, 2, subplot_kw={\"projection\": ccrs.EqualEarth()})\n",
    "axs_scatter = subfigs[1].subplots(1, 3)\n",
    "ax_bar = subfigs[2].subplots(1, 1)\n",
    "\n",
    "axs_rmse, axs_nse = axs_geo\n",
    "\n",
    "### MAP PLOTS ###\n",
    "\n",
    "# Grid scale plots\n",
    "our_rmse_grid.dr.projplot(vmin=0, vmax=100, ax=axs_rmse[0], **rmse_kwargs)\n",
    "our_nse_grid.dr.projplot(vmin=0.0, vmax=1.0, ax=axs_nse[0], **nse_kwargs)\n",
    "\n",
    "# Basin scale plots\n",
    "our_rmse_basin.dr.projplot_basins(\n",
    "    our_rmse_grid,\n",
    "    vmin=0,\n",
    "    vmax=50,\n",
    "    ax=axs_rmse[1],\n",
    "    **rmse_kwargs,\n",
    ")\n",
    "our_nse_basin.dr.projplot_basins(\n",
    "    our_nse_grid,\n",
    "    vmin=0.7,\n",
    "    vmax=1.0,\n",
    "    ax=axs_nse[1],\n",
    "    **nse_kwargs,\n",
    ")\n",
    "\n",
    "# Add basinlines\n",
    "for ax in [axs_rmse[1], axs_nse[1]]:\n",
    "    gdf_basin_shapes.dr.projplot(ax=ax, **basinlines_kwargs)\n",
    "\n",
    "# Titles\n",
    "time_str_our = f\"{times_our[0].year}--{times_our[-1].year}\"\n",
    "axs_rmse[0].set(title=\"Grid scale, \" + time_str_our)\n",
    "axs_rmse[1].set(title=\"Basin scale, \" + time_str_our)\n",
    "\n",
    "### SCATTER PLOT ###\n",
    "\n",
    "for i, (ax, (name, df)) in enumerate(zip(axs_scatter, df_comps.items())):\n",
    "    sns.scatterplot(\n",
    "        df,\n",
    "        x=target_name,\n",
    "        y=our_name,\n",
    "        ax=ax,\n",
    "        size=\"area\",\n",
    "        legend=True if i == 0 else False,\n",
    "    )\n",
    "\n",
    "    # Unpack dicts\n",
    "    name_verbose = names_verbose[name]\n",
    "    unit = units[name]\n",
    "    lim = lims[name]\n",
    "    loc = locs[name]\n",
    "    pcc = pcc_scores[name]\n",
    "\n",
    "    ax.set(\n",
    "        title=name_verbose,\n",
    "        xlabel=f\"CSR ({unit})\",\n",
    "        ylabel=f\"DeepRec ({unit})\",\n",
    "        xlim=lim,\n",
    "        ylim=lim,\n",
    "        aspect=\"equal\",\n",
    "    )\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "    # Add diagonal line\n",
    "    ax.plot(\n",
    "        lim,\n",
    "        lim,\n",
    "        color=\"gray\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        zorder=0,\n",
    "    )\n",
    "\n",
    "    # Add PCC score\n",
    "    ax.text(1.0, 0.07, f\"PCC = {pcc:.2f}\", ha=\"right\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "# Place legend outside of axes\n",
    "axs_scatter[0].legend().remove()\n",
    "legend = subfigs[1].legend(loc=\"outside right\", title=\"Area\\n($10^6$ km$^2$)\")\n",
    "legend.get_title().set_ha(\"center\")\n",
    "\n",
    "### BAR CHART ###\n",
    "\n",
    "sns.barplot(\n",
    "    df_rmse_avg,\n",
    "    x=\"rmse\",\n",
    "    y=\"model\",\n",
    "    hue=\"scale\",\n",
    "    width=0.6,\n",
    "    gap=0.1,\n",
    "    ax=ax_bar,\n",
    "    palette=\"Paired\",\n",
    "    order=my_order,\n",
    ")\n",
    "time_str_all = f\"{times_all[0].year}--{times_all[-1].year}\"\n",
    "ax_bar.set(\n",
    "    xlabel=\"RMSE (mm)\",\n",
    "    ylabel=None,\n",
    "    xlim=(0, 100),\n",
    "    title=\"Global average error, \" + time_str_all,\n",
    ")\n",
    "ax_bar.xaxis.grid()\n",
    "# Place legend outside of axis\n",
    "ax_bar.legend().remove()\n",
    "subfigs[2].legend(loc=\"outside right\")\n",
    "\n",
    "### LETTERS ###\n",
    "\n",
    "for n, ax in enumerate(axs_geo.flat):\n",
    "    ax.text(\n",
    "        0.0,\n",
    "        1.0 - 0.08,\n",
    "        string.ascii_lowercase[n],\n",
    "        transform=ax.transAxes,\n",
    "        size=\"x-large\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "for n, ax in enumerate(axs_scatter):\n",
    "    ax.text(\n",
    "        0.0,\n",
    "        1.0 + 0.15,\n",
    "        string.ascii_lowercase[len(axs_geo.flat) + n],\n",
    "        ha=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "        size=\"x-large\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "ax_bar.text(\n",
    "    0.0,\n",
    "    1.0 + 0.06,\n",
    "    string.ascii_lowercase[len(axs_geo.flat) + len(axs_scatter.flat)],\n",
    "    ha=\"center\",\n",
    "    transform=ax_bar.transAxes,\n",
    "    size=\"x-large\",\n",
    "    weight=\"bold\",\n",
    ")\n",
    "\n",
    "fig.savefig(FIGURE_DIR / \"grace_comp_r.pdf\", backend=\"pgf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
